qplot(inTrain, CompressiveStrength, data=training)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
summary(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list = false)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list = FALSE)
training <- segmentationOriginal[inTrain]
training
training <- segmentationOriginal[inTrain,]
training <- segmentationOriginal[-inTrain,]
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[inTrain,]
unique(segmentationOriginal$Case)
segmentationOriginal$Case
summary(segmentationOriginal)
modFit<-train(Class~., method="rpart", data=training)
library(rattle)
install.packages("rattle")
install.packages("RGtk2")
install.packages("GTK")
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
test2<-data.frame(TotalIntench2=23000, FiberWidthCh1=10, PerimStatusCh1=2)
test2
rbind(test2,data.frame(TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100)
rbind(test2,data.frame(TotalIntench2 = 50,000, FiberWidthCh1 = 10,VarIntenCh4 = 100)
)
test2$VarIntenCh4<-NA
test2
is.na(test2)
complete.cases(test2)
rbind(test2,data.frame(TotalIntench2 = 50000, FiberWidthCh1 = 10, VarIntenCh4 = 100))
rbind(test2,data.frame(TotalIntench2 = 50000, FiberWidthCh1 = 10, VarIntenCh4 = 100, PerimStatusCh1=NA))
test2
test2<-rbind(test2,data.frame(TotalIntench2 = 50000, FiberWidthCh1 = 10, VarIntenCh4 = 100, PerimStatusCh1=NA))
test2<-rbind(test2,data.frame(TotalIntench2 = 57000, FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=NA))
test2<-rbind(test2,data.frame(FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2, TotalIntench2=NA))
test2
predict(modFit,data=test2)
predict(modFit,newdata=test2)
predict(modFit,newdata=testing)
testing[testing$TotalIntench2=23000 && testing$FiberWidthCh1=10 && testing$PerimCh1=2]
testing[testing$TotalIntench2==23000 && testing$FiberWidthCh1==10 && testing$PerimCh1==2,]
testing[testing$TotalIntench2==23000 && testing$FiberWidthCh1==10 && testing$PerimCh1==2]
testing[testing$TotalIntench2==23000 & testing$FiberWidthCh1==10 & testing$PerimCh1==2]
testing[testing$TotalIntench2==23000 & testing$FiberWidthCh1==10 & testing$PerimCh1==2,]
testing[testing$TotalIntench2==23000 & testing$FiberWidthCh1==10 & testing$PerimCh1==2]
head(testing[testing$TotalIntench2==23000 & testing$FiberWidthCh1==10 & testing$PerimCh1==2])
testing
head(testing[testing$TotalIntench2==23000 & testing$FiberWidthCh1==10 & testing$PerimCh1==2])
testing[testing$TotalIntench2==23000 & testing$FiberWidthCh1==10 & testing$PerimCh1==2,]
testing$TotalIntench2==23000
testing
testing$TotalIntenCh2==23000
testing$TotalIntenCh2==23000
testing$Case=="Test"
testing<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
testing$Case
testing$Case=="Train"
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
set.seed(125)
modFit<-train(Class~., method="rpart", data=training)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
predict(modFit,newdata=test2)
test2
names(testing)
names(test2)<-c("TotalIntenCh2", "FiberWidthCh1", "PerimStatusCh1", "VarIntenCh4")
test2
predict(modFit,newdata=test2)
unique(testing$TotalIntenCh2)
testing$TotalIntenCh2==23000
table(testing$TotalIntenCh2==23000)
table(testing$TotalIntenCh2==50000)
modFit<-train(Class~TotalIntenCh2+FiberWidthCh1+PerimStatusCh1+VarIntenCh4, method="rpart", data=training)
predict(modFit,newdata=test2)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
test2
predict(modFit,newdata=test2)
modFit$finalModel
predict(modFit$inalModel,newdata=test2)
predict(modFit$finalModel,newdata=test2)
predict(modFit,newdata=test2)
predict(modFit$finalModel,newdata=test2)
training$Case
set.seed(125)
modFit<-train(Class~TotalIntenCh2+FiberWidthCh1+PerimStatusCh1+VarIntenCh4, method="rpart", data=training)
predict(modFit,newdata=test2)
modFit$pred
modFit$trainingData
modFit$coefnames
modFit$results
predict(modFit,newdata=test2)
predict(modFit$finalModel,newdata=test2)
testing$TotalIntenCh2==23000
unique(testing$TotalIntenCh2==23000)
unique(testing$TotalIntenCh2)
unique(testing$TotalIntenCh2==1047)
predict(modFit,newdata=test2)
predict(modFit$finalModel,newdata=test2)
predict(modFit, test2)
?predict
iris
inTrainIris<-createDataPartition(y=iris$Species,p=0.7,list=FALSE)
trainingIris<-iris[inTrainIris,]
testingIris<-iris[-inTrainIris,]
modFitIris<-train(Species~.,method="rpart",data=trainingIris)
predict(modFitIris, testingIris)
modFit<-train(Class~., method="rpart", data=training)
modFit$finalModel
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
t(c(1,2))
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
names(olive)
olive = olive[,-1]
names(olive)
colMeans(olive)
t(colMeans(olive))
modFitOlive<-train(Area~., method="rpart", data=olive)
olive
newdata = as.data.frame(t(colMeans(olive)))
predict(modFitOlive, newdata)
olive$Area
summary(olive)
?olive
data(olive)
olive
names(olive)
unique(olive$Region)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
names(trainSA)
modFitSA<-train(chd~age+alchol+obesity+tobacco+typea+ldl, method="glm", data=trainSA, family="binomial")
modFitSA<-train(chd~age+alcohol+obesity+tobacco+typea+ldl, method="glm", data=trainSA, family="binomial")
trainSA$chd
trainSA$chd<-as.factor(trainSA$chd)
modFitSA<-train(chd~age+alcohol+obesity+tobacco+typea+ldl, method="glm", data=trainSA, family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,modFitSA$results)
modFitSA$results
modFitSA$pred
missClass(trainSA$chd,predict(modFitSA, trainSA))
missClass(as.numeric(trainSA$chd),predict(modFitSA, trainSA))
predict(modFitSA, trainSA)
trainSA$chd<-as.numeric(trainSA$chd)
modFitSA<-train(chd~age+alcohol+obesity+tobacco+typea+ldl, method="glm", data=trainSA, family="binomial")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
modFitSA<-train(chd~age+alcohol+obesity+tobacco+typea+ldl, method="glm", data=trainSA, family="binomial")
missClass(as.numeric(trainSA$chd),predict(modFitSA, trainSA))
missClass(as.numeric(trainSA$chd),predict(modFitSA, testSA))
missClass(trainSA$chd,predict(modFitSA, testSA))
missClass(testSA$chd,predict(modFitSA, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
modFitVowel<-train(y~.,method="rf",data=vowel.train)
modFitVowel<-train(y~.,method="rf",data=vowel.train)
varImp(modFitVowel)
modFitVowel<-train(y~.,method="rf",data=vowel.train)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
modFitVowel<-train(y~.,method="rf",data=vowel.train)
library(caret)
modFitVowel<-train(y~.,method="rf",data=vowel.train)
modFitVowel2<-train(y~.,method="gbm",data=vowel.train)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
library(caret)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
modFitVowel<-train(y~.,method="rf",data=vowel.train)
modFitVowel2<-train(y~.,method="gbm",data=vowel.train)
dim(vowel.test)
modFitVowel
predict(modFitVowel, vowel.test)
confusionMatrix(predict(modFitVowel, vowel.test))
confusionMatrix(predict(modFitVowel, vowel.test), vowel.test$y)
confusionMatrix(predict(modFitVowel, vowel.test), vowel.test$y)
confusionMatrix(predict(modFitVowel2, vowel.test), vowel.test$y)
table(predict(modFitVowel, vowel.test), vowel.test$y)
sum(predict(modFitVowel,vowel.test)==vowel.test$y)
sum(predict(modFitVowel,vowel.test)==vowel.test$y)/dim(vowel.test)[1]
confusionMatrix(predict(modFitVowel, vowel.test))
confusionMatrix(predict(modFitVowel, vowel.test), vowel.test$y)
set.seed(33833)
modFitVowel<-train(y~.,method="rf",data=vowel.train)
confusionMatrix(predict(modFitVowel, vowel.test), vowel.test$y)
confusionMatrix(predict(modFitVowel, vowel.test), vowel.test$y)
modFitVowel<-train(y~.,method="rpart",data=vowel.train)
confusionMatrix(predict(modFitVowel, vowel.test), vowel.test$y)
modFitVowel<-train(y~.,method="rf",data=vowel.train)
confusionMatrix(predict(modFitVowel, vowel.test), vowel.test$y)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modFitRF<-train(diagnosis~.,data=adData,method="rf")
modFitGBM<-train(diagnosis~.,data=adData,method="gbm")
modFitLDA<-train(diagnosis~.,data=adData,method="lda")
modFitRF<-train(diagnosis~.,data=training,method="rf")
modFitGBM<-train(diagnosis~.,data=training,method="gbm")
modFitGBM<-train(diagnosis~.,data=training,method="lda")
modFitLDA<-train(diagnosis~.,data=training,method="lda")
modFitGBM<-train(diagnosis~.,data=training,method="gbm")
confusionMatrix(predict(modFitRF, testing), testing$diagnostic)
confusionMatrix(predict(modFitRF, testing[-diagnostic]), testing$diagnostic)
confusionMatrix(predict(modFitRF, testing), testing$diagnosis)
confusionMatrix(predict(modFitGBM, testing), testing$diagnosis)
confusionMatrix(predict(modFitLDA, testing), testing$diagnosis)
confusionMatrix(predict(modFitRF, testing), testing$diagnosis)
confusionMatrix(predict(modFitLDA, testing), testing$diagnosis)
confusionMatrix(predict(modFitGBM, testing), testing$diagnosis)
newPred<-data.frame(predict(modFitRF, testing), predict(modFitGBM, testing), predict(modFitLDA, testing))
newPredTrain<-data.frame(predict(modFitRF, training), predict(modFitGBM, training), predict(modFitLDA, training))
newPred<-data.frame(predict(modFitRF, testing), predict(modFitGBM, testing), predict(modFitLDA, testing), diagnosis=testing$diagnosis)
newPred
modFitComb<-train(diagnosis~.,method="rf",data=newPred)
confusionMatrix(predict(modFitComb, newPred), testing$diagnosis)
newPredTrain<-data.frame(predict(modFitRF, training), predict(modFitGBM, training), predict(modFitLDA, training), diagnosis=training$diagnosis)
modFitComb<-train(diagnosis~.,method="rf",data=newPredTrain)
confusionMatrix(predict(modFitComb, newPred), testing$diagnosis)
newPredTrain
names(newPredTrain)
newPred<-data.frame(predict.modFitRF..training.=predict(modFitRF, testing), predict.modFitGBM..training.=predict(modFitGBM, testing), predict.modFitLDA..training.=predict(modFitLDA, testing), diagnosis=testing$diagnosis)
confusionMatrix(predict(modFitComb, newPred), testing$diagnosis)
confusionMatrix(predict(modFitGBM, testing), testing$diagnosis)
predict.modFitLDA..training.
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
modFitLasso<-train(CompressiveStrength~.,method="lasso",data=concrete)
modFitLasso<-train(CompressiveStrength~.,method="lasso",data=concrete)
modFitLass
modFitLasso
?plot.enet
plot.enet(modFitLasso, xvar = c("fraction", "penalty", "L1norm", "step"))
plot.enet(modFitLasso)
modFitLasso$modelInfo
modFitLasso$coefnames
modFitLasso$xlevels
modFitLasso$pred
modFitLasso$bestTune
modFitLasso$results
modFitLasso$finalModel
x
modFitLasso$finalModel
plot(modFitLasso$finalModel)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
modFitSVM<-train(CompressiveStrength~.,method="e1071",data=training)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
modFitLasso<-train(CompressiveStrength~.,method="lasso",data=training)
plot(modFitLasso$finalModel)
modFitLasso<-train(CompressiveStrength~.,method="lasso",data=training)
plot(modFitLasso$finalModel)
plot(modFitLasso$finalModel)
modFitLasso$finalModel
?enet
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
modFitSVM<-train(CompressiveStrength~.,method="e1071",data=training)
modFitSVM->svm(CompressiveStrength~.,data=training)
modFitSVM<-svm(CompressiveStrength~.,data=training)
confusionMatrix(predict(modFitSVM, testing), testing$CompressiveStrength)
confusionMatrix(predict(modFitSVM, testing), testing$CompressiveStrength)
predict(modFitSVM, testing)
sqrt(mean((predict(modFitSVM, testing)-testing$CompressiveStrength)^2))
pwd
getwd()
gaData <- read.csv("~/DataScienceCoursera/gaData.csv")
View(gaData)
dat<-gaData
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)
install.packages("lubridate")
library(lubridate)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
training
tsTra
tstrain
library(forecast)
install.packages("forecast")
library(forecast)
bats(tstrain)
modFitBats<-bats(tstrain)
forecast(tstrain)
tstrain
ts(testing$visitsTumblr)
tstrain
forecast(tstrain)
plot(forecast(tstrain))
lines(ts(testing),col="red")
lines(ts(testing$visitsTumblr),col="red")
lines(ts(testing$visitsTumblr,start = 366),col="red")
plot(forecast(tstrain,h = 365))
plot(forecast(tstrain,h = 365,level = 95))
lines(ts(testing$visitsTumblr),col="red")
lines(ts(testing$visitsTumblr,start = 366),col="red")
forecast(tstrain,h=365,level=95)
tstest<-ts(testing$visitsTumblr,start = 366)
tstest
fcast<-forecast(tstrain,h=365,level=95)
accuracy(fcast,tstest)
fcast
fcast$upper
length(tstest)
dim(fcast)
tsPredBound<-data.frame(fcast$lower, fcast$upper)
tsPredBound
tsPredBound[1:235,]
tsPredBound<-tsPredBound[1:235,]
length(tstest)
sum(tstest[(tstest>=tsPredBound$Series.1 & tstest<=tsPredBound$Series.1.1])])
sum(tstest[(tstest>=tsPredBound$Series.1 & tstest<=tsPredBound$Series.1.1)])
count(tstest[(tstest>=tsPredBound$Series.1 & tstest<=tsPredBound$Series.1.1)])
sum(count(tstest[(tstest>=tsPredBound$Series.1 & tstest<=tsPredBound$Series.1.1)]))
tstest[(tstest>=tsPredBound$Series.1 & tstest<=tsPredBound$Series.1.1)]
length(tstest[(tstest>=tsPredBound$Series.1 & tstest<=tsPredBound$Series.1.1)])/length(tstest)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
modFitLasso<-train(CompressiveStrength~.,method="lasso",data=training)
plot(modFitLasso$finalModel)
modFitLasso$finalModel
trainData<-read.csv("pml-training.csv", header = TRUE)
testData<-read.csv("pml-testing.csv", header = TRUE)
setwd("PracticalMachineLearningProject/")
trainDataFiltered<-trainData[,names(trainData)[grep('(belt|dumbbell|arm|forearm)',names(trainData))]]
trainDataFiltered$classe<-trainData$classe
trainDataFiltered[trainDataFiltered==""]<-NA
trainDataFiltered<-trainDataFiltered[,colSums(is.na(trainDataFiltered))<dim(trainDataFiltered)[1]/2]
trainDataFiltered<-trainData[,names(trainData)[grep('(belt|dumbbell|arm|forearm)',names(trainData))]]
trainDataFiltered$classe<-trainData$classe
trainDataFiltered[trainDataFiltered==""]<-NA
trainDataFiltered<-trainDataFiltered[,colSums(is.na(trainDataFiltered))<dim(trainDataFiltered)[1]/2]
trainDataFiltered<-trainData[,names(trainData)[grep('(belt|dumbbell|arm|forearm)',names(trainData))]]
trainDataFiltered$classe<-trainData$classe
trainDataFiltered[trainDataFiltered==""]<-NA
trainDataFiltered<-trainDataFiltered[,colSums(is.na(trainDataFiltered))<dim(trainDataFiltered)[1]/2]
trainData<-read.csv("pml-training.csv", header = TRUE)
testData<-read.csv("pml-testing.csv", header = TRUE)
trainDataFiltered<-trainData[,names(trainData)[grep('(belt|dumbbell|arm|forearm)',names(trainData))]]
trainDataFiltered$classe<-trainData$classe
trainDataFiltered[trainDataFiltered==""]<-NA
trainDataFiltered<-trainDataFiltered[,colSums(is.na(trainDataFiltered))<dim(trainDataFiltered)[1]/2]
require(caret)
trainDataFiltered<-predict(preProcess(trainDataFiltered[,-(dim(trainDataFiltered)[2])], method=c("center","scale")),trainDataFiltered[,-(dim(trainDataFiltered)[2])])
trainDataFiltered$classe<-trainData$classe
set.seed(3233)
train_control <- trainControl(method="cv", number=5)
modelRPart <- train(classe~., data=trainDataFiltered, trControl=train_control, method="rpart")
modelRPart$pred
modelRPart$results
modelGBM <- train(classe~., data=trainDataFiltered, trControl=train_control, method="gbm")
confusionMatrix.train(modelRPart)
confusionMatrix.train(modelGBM)
modelGBM$results
print(modelRPart)
print(modelGBM)
modelLDA <- train(classe~., data=trainDataFiltered, trControl=train_control, method="lda")
modelLDA$results
modelLDA$results$Accuracy
modelRPart$results$Accuracy
modelRPart$results$Accuracy
modelGBM$results$Accuracy
which.max(modelGBM$results$n.minobsinnode)
modelGBM$results$n.minobsinnode
modelGBM$results$n.trees
modelGBM$results$shrinkage
modelGBM$results$trees
modelGBM$results$Accuracy
which.max(modelGBM$results$Accuracy)
modelGBM$results$Accuracy[which.max(modelGBM$results$Accuracy)]
modelRPart$results$Accuracy[which.max(modelRPart$results$Accuracy)]
modelGBM$results$Accuracy[which.max(modelGBM$results$Accuracy)]
modelLDA$results$Accuracy[which.max(modelLDA$results$Accuracy)]
testDataFiltered<-testData[,names(trainData)[grep('(belt|dumbbell|arm|forearm)',names(testData))]]
dim(testDataFiltered)
dim(trainDataFiltered)
testDataFiltered<-testData[,names(testData)[grep('(belt|dumbbell|arm|forearm)',names(testData))]]
dim(testDataFiltered)
View(testData)
names(trainDataFiltered)
dim(trainData)
testDataFiltered<-testData[,names(trainDataFiltered)]
names(trainDataFiltered)
names(trainDataFiltered)[-1]
names(trainDataFiltered)[-52]
names(trainDataFiltered)[-51]
names(trainDataFiltered)[1:51]
names(trainDataFiltered)[1:52]
names(trainDataFiltered)[1:53]
names(trainDataFiltered)[1:54]
names(trainDataFiltered)[-53
]
names(trainDataFiltered)[-53]
names(trainDataFiltered)[-52
]
testDataFiltered<-testData[,names(trainDataFiltered)[-53]]
dim(testDataFiltered)
View(testDataFiltered)
testDataFiltered<-predict(preProcess(trainDataFiltered[,-(dim(trainDataFiltered)[2])], method=c("center","scale")),testDataFiltered)
predict(modelGBM, testDataFiltered)
predict(modelGBM, newData=testDataFiltered)
predict(modelGBM, newdata = testDataFiltered)
testDataFiltered<-testData[,names(trainDataFiltered)[-53]]
predict(modelGBM, newdata = testDataFiltered)
testData<-read.csv("pml-testing.csv", header = TRUE)
testDataFiltered<-testData[,names(trainDataFiltered)[-53]]
names(testDataFiltered)
names(trainDataFiltered)
predict(modelLDA, testDataFiltered)
predict(modelGBM$finalModel, testDataFiltered)
modelGBM$finalModel
modelGBM$pred
modelGBM$bestTune
modelGBM$coefnames
predict(modelLDA, testDataFiltered)
modelGBM$finalModel
modelGBM$method
modelGBM$modelInfo
modelGBM$trainingData
modelGBM$results$Accuracy
modelGBM$results
predict.gbm(modelGBM, newdata = testDataFiltered, n.trees = 150)
predict(modelGBM, newdata = testDataFiltered, n.trees = 150)
predict(modelRPart, testDataFiltered)
confusionMatrix(trainDataFiltered$classe, predict(modelGBM, trainDataFiltered[-(dim(trainDataFiltered[2]))]))
confusionMatrix(trainDataFiltered$classe, predict(modelGBM, trainDataFiltered[-(dim(trainDataFiltered)[2])]))
View(testDataFiltered)
]testDataFiltered<-predict(preProcess(trainDataFiltered[,-(dim(trainDataFiltered)[2])], method=c("center","scale")),testDataFiltered)
]testDataFiltered<-predict(preProcess(trainDataFiltered[,-(dim(trainDataFiltered)[2])], method=c("center","scale")),testDataFiltered)
testDataFiltered<-predict(preProcess(trainDataFiltered[,-(dim(trainDataFiltered)[2])], method=c("center","scale")),testDataFiltered)
predict(modelGBM, newdata = testDataFiltered, n.trees = 150)
View(testDataFiltered)
View(trainDataFiltered)
View(head(trainData))
View(head(trainData[,names]))
View(head(trainData[,names(trainDataFiltered)]))
View(head(testData[,names(trainDataFiltered)]))
View(head(testData[,names(trainDataFiltered)]))
View(head(testData[,names(trainDataFiltered[-53])]))
require(caret)
